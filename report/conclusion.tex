We have implemented a fully-functional rock slicing module in Scala that runs in parallel on the Apache Spark platform. In general, the abstractions offered by the Scala/Spark programming model allowed us to write clean and concise code. We also fully tested our implementation (our unit tests, along with all of our code, can be found on our GitHub repository\footnote{\url{https://github.com/shellshocked2003/cs267-project}}) and are therefore confident that our algorithm works correctly. The rock slicing algorithm performs adequately but not as efficiently as we would have liked. Strong scaling results are favorable, and our implementation is substantially faster than the original serial algorithm featured in \cite{slicing}, but we ran into difficulties with weak scaling and addressing problems related to data skew across Spark's RDD partitions.

We have attempted to identify and analyze some of the key parameters that could be used to tune the performance of our algorithm in sections 4 and 5, such as RDD partition count and repartitioning frequency. Unfortunately, we were not able to run all of the necessary experiments and analysis to fully tune our algorithm for deployment on Spark due to time constraints. This could probably be a project in and of itself. Moreover, as we were learning Scala and Spark during the course of this project, we likely are not yet comfortable enough with Scala and Spark to fully exploit their respective feature sets. We look forward to learning more about these programming tools and being able to use them more effectively in the future. We believe that, with more experience using Spark as well as more performance experiments, we will be able to significantly improve the performance of our rock slicing algorithm.

The primary motivation for this project was the general lack of open source rock slicing tools available to the geotechnics community, let alone open and parallel rock slicing tools. Boon did formulate the original serial algorithm that we used as the basis of our implementation, but only a small subset of his code is publicly available. Furthermore, the current standard in the engineering community is to use proprietary tools, which often feature serial implementations. While our code does not outperform Boon's implementation to the extent we would like, the fact that it does beat this implementation makes it the fastest rock slicing algorithm that we know of. It is also able to operate at a larger scale than competing rock slicing software by processing much larger input datasets, and we believe our lead will only grow once we improve our algorithm's interaction with Spark.

Our ultimate goal was to implement a tool that would be useful for engineers in the real world. To that end, we plan to extend our implementation to include support for processing LiDAR scans of rock formations as input data and also plan to implement discrete element modeling on Spark. This second task will likely be difficult due to the lack of expressive communication primitives in Spark. We plan to consult with the Spark development team as they work on new means of communication in the near future. We hope that we will eventually be able to offer an attractive, high-performance framework for geologists and geoengineers to use for the analysis and simulation of jointed rock masses.